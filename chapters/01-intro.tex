\chapter{Introduction}\label{ch:introduction}

Many applications today perform real-time monitoring and analytics on
potentially unbounded streams of data. Examples of this include analytics for
commercial web applications and social networks, online processing of sensor
data, and monitoring and networking in datacenters. In many deployments however,
the number of data sources and the amount and complexity of queries will increase
over time, and thus the need for management systems and expressive programming
models for online stream processing arises.

\vspace{0.66em}
In this thesis, we investigate the architecture and implementation of a
management system for running computations written in the \emph{timely
dataflow} programming model.
\vspace{0.66em}

Timely dataflow is a programming model for a wide range of data-parallel algorithms.
It has first been implemented and introduced in the Naiad system \cite{naiad}.
The timely dataflow model has been successfully used for stream and graph
processing, and it is the central building block for
higher-level abstractions such as differential dataflow \cite{differential}.
Timely dataflow supports stateful operators and iterative computations, while
achieving high throughput and low-latency responses thanks to a decentralized
coordination mechanism for global progress tracking. Our work
builds upon the Rust implementation of the timely dataflow model,
simply called \textquote{Timely Dataflow}\footnote{We use the capitalized term
for the implementation, while the model is referred to in lower-case.} \cite{timely}.

\section{Contributions}

Being an embeddable library, the current runtime of Timely Dataflow only
concerns itself with the execution and scheduling of a single processing job.
This results in a tendency towards large, monolithic dataflow graphs which
perform many different tasks at the same time. While these monolithic computations
are highly efficient in terms of resource usage, this comes at a cost with regard
to maintainability and extensibility. Attaching an additional stage to a monolithic
dataflow graph cannot be done for an online computation without restarting the
whole application.

While Timely Dataflow does support the distributed execution of a dataflow computation
on a statically sized cluster, launching and deployment of the the compiled
application binary has to be done manually by the user: They have to provide the
addresses of all participating machines to each process separately.

The contribution of this thesis is the design and implementation of a system which
aims to improve the deployment of Timely Dataflow by providing the following
features:

- 

\begin{itemize}
\item Handling of the deployment and execution of multiple concurrent dataflow programs.
\item Providing interfaces for the submission of dataflow programs.
\item Dynamic addition and limited removal of machines to the cluster.
\item Managing of data streams consumed and produced by the running dataflow computations.
\item Allowing system introspection by exposing metadata about the current system state.
\end{itemize}

\TODO{sketch how this is relevant}

\section{Outline}

In chapter \ref{ch:background}, we provide a brief overview of
the Timely Dataflow library, its conceptual model and its implementation. The
system designed and implemented as part of this thesis is introduced and
discussed in detail in the chapters \ref{ch:design} \& \ref{ch:impl}. As our
system allows the dynamic composition of dataflow programs, we evaluate the
overhead of this feature on a realistic workload in chapter \ref{ch:evaluation}.
A survey of related work is presented in chapter \ref{ch:related}, and chapter
\ref{ch:future} closes with future work and conclusions.
