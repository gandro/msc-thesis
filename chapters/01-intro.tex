\chapter{Introduction}\label{ch:introduction}

Many applications today perform real-time monitoring and analytics on
potentially unbounded streams of data. Examples of this include analytics for
commercial web applications and social networks, online processing of sensor
data, and monitoring and networking in datacenters. In many deployments however,
the number of data sources and the amount and complexity of queries will increase
over time, and thus the need for management systems and expressive programming
models for online stream processing arises.

\vspace{0.66em}
In this thesis, we investigate the architecture and implementation of a
management system for running computations written in the \emph{timely
dataflow} programming model.
\vspace{0.66em}

Timely dataflow is a programming model for a wide range of data-parallel algorithms.
It has first been implemented and introduced in the Naiad system \cite{naiad}.
The timely dataflow model has been successfully used for stream and graph
processing, and it is the central building block for
higher-level abstractions such as differential dataflow \cite{differential}.
Timely dataflow supports stateful operators and iterative computations, while
achieving high throughput and low-latency responses thanks to a decentralized
coordination mechanism for global progress tracking. Our work
builds upon the Rust implementation of the timely dataflow model,
simply called \textquote{Timely Dataflow}\footnote{We use the capitalized term
for the implementation, while the model is referred to in lower-case.} \cite{timely}.

Being an embeddable library, the current runtime of Timely Dataflow only
concerns itself with the execution and scheduling of a single processing job.
This results in a tendency towards large, monolithic dataflow graphs which
perform many different tasks at the same time. While these monolithic computations
are highly efficient in terms of resource usage, this comes at a cost with regard
to maintainability and extensibility. Attaching an additional stage to a monolithic
dataflow graph cannot be done for an online application without restarting the
whole computation.

Furthermore, while Timely Dataflow does support the distributed execution of
a dataflow computation on a statically sized cluster, launching and deployment
of the compiled application binary has to be done manually by the user. This
can quickly become inconvenient if many different dataflow computations have
to be deployed.

While Timely Dataflow has been successfully used for online streaming applications,
we believe that further improvements can be made in terms of usability and composability.
Specifically, we wish to ease the deployment of multiple concurrent
dataflow computations, the management of the compute cluster, and we want to
assist with the use of shared data sources.

\section{Contributions}

The contribution of this thesis is the design and implementation of a system
for the deployment of Timely Dataflow applications. It provides the following
features:

\begin{itemize}
\item Handling the submission and execution of multiple concurrent dataflow programs.
\item Dynamic addition and limited removal of machines to the cluster.
\item An integrated publish/subscribe system which allows dataflow programs to share their produced streams
      for consumption by other running computations.
\item Enabling system introspection by exposing metadata about the current system state.
\end{itemize}

\section{Outline}

In chapter \ref{ch:background}, we provide a brief overview of
the Timely Dataflow library, its conceptual model and its implementation. The
system designed and implemented as part of this thesis is introduced and
discussed in detail in the chapters \ref{ch:design} \& \ref{ch:impl}. As our
system allows the dynamic composition of dataflow programs, we evaluate the
overhead of this feature on a realistic workload in chapter \ref{ch:evaluation}.
A survey of related work is presented in chapter \ref{ch:related}, and chapter
\ref{ch:future} closes with future work and conclusions.
